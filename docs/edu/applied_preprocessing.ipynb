{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Preprocess for Real\n",
    "\n",
    "This tutorial intends to show ``preprocess`` in a real context. After a \n",
    "quickstart in the library, and the bases of text normalization with \n",
    "python, the next obvious step is to apply preprocessing techniques in a \n",
    "real NLP problem\n",
    "\n",
    "The selected problem is *Semantic Text Similarity*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Text Similarity\n",
    "\n",
    "SEMEVAl is an International Workshop on Semantic Evaluation, currently\n",
    "part of Lexical and Computational Semantic and Semantic Evaluation\n",
    "scientific conference. The objective of this workshop is to measure\n",
    "the degree of semantic equivalence between two texts. The data is\n",
    "composed by sentence pairs, coming from previously existing paraphrase\n",
    "datasets [Agirre2012]_. This event is divided in tasks, the task of \n",
    "interest here is [Semantic Text Similarity](http://alt.qcri.org/semeval2012/task17/)\n",
    "\n",
    "Usually in the gold standard the semantic equivalence is measured with\n",
    "a float number between [0-5]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The data used for this example is a small part of SemEval 2012 Shared\n",
    "[Task 6 Dataset](https://www.cs.york.ac.uk/semeval-2012/task6/index.php%3Fid=data.html), the en-en subset.\n",
    "\n",
    "The subset is from MSR-Paraphrase, [Microsoft Research Paraphrase Corpus](http://research.microsoft.com/en-us/downloads/607d14d9-20cd-47e3-85bc-a2f65cd28042/).\n",
    "750 pairs of sentences.\n",
    "\n",
    "### Legal Note\n",
    "\n",
    "STS 2012 Dataset is under this licenses:\n",
    "* http://research.microsoft.com/en-us/downloads/607d14d9-20cd-47e3-85bc-a2f65cd28042/\n",
    "* http://research.microsoft.com/en-us/downloads/38cf15fd-b8df-477e-a4e4-a4680caa75af/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dataset\n",
    "import pandas as pd\n",
    "data = pd.read_csv('../../preprocess/data/2012SMTeuroparl.train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.25</td>\n",
       "      <td>I know that in France they have had whole herd...</td>\n",
       "      <td>I know that in France, the principle of slaugh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.80</td>\n",
       "      <td>Unfortunately, the ultimate objective of a Eur...</td>\n",
       "      <td>Unfortunately the final objective of a Europea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.80</td>\n",
       "      <td>The right of a government arbitrarily to set a...</td>\n",
       "      <td>The right for a government to draw aside its c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>The House had also fought, however, for the re...</td>\n",
       "      <td>This Parliament has also fought for this reduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.80</td>\n",
       "      <td>The right of a government arbitrarily to set a...</td>\n",
       "      <td>The right for a government to dismiss arbitrar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                                 s1  \\\n",
       "0   4.25  I know that in France they have had whole herd...   \n",
       "1   4.80  Unfortunately, the ultimate objective of a Eur...   \n",
       "2   4.80  The right of a government arbitrarily to set a...   \n",
       "3   4.00  The House had also fought, however, for the re...   \n",
       "4   4.80  The right of a government arbitrarily to set a...   \n",
       "\n",
       "                                                  s2  \n",
       "0  I know that in France, the principle of slaugh...  \n",
       "1  Unfortunately the final objective of a Europea...  \n",
       "2  The right for a government to draw aside its c...  \n",
       "3  This Parliament has also fought for this reduc...  \n",
       "4  The right for a government to dismiss arbitrar...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = ['score','s1','s2']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "Thise example use the open source library [textsim](https://github.com/sorice/textsim), \n",
    "a personal proyect of the author. Is a library for text similarity \n",
    "which integrates some very known text similarity distances, and some \n",
    "implementation of those distances on scipy, sklearn and other python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "import textsim\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lowercase',\n",
       " 'replace_urls',\n",
       " 'replace_symbols',\n",
       " 'replace_dot_sequence',\n",
       " 'multipart_words',\n",
       " 'expand_abbrevs',\n",
       " 'normalize_abbrevs',\n",
       " 'expand_contractions',\n",
       " 'replace_punctuation',\n",
       " 'extraspace_for_endingpoints',\n",
       " 'add_doc_ending_point',\n",
       " 'del_tokens_len_one',\n",
       " 'hyphenation',\n",
       " 'del_digits']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.basic.__all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abelma/vnlp/lib/python3.8/site-packages/pandas/core/generic.py:5159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "#You can play with the atomic steps preproc-text library allows\n",
    "flow = ['lowercase', \n",
    "        'expand_contractions', \n",
    "        'replace_dot_sequence', \n",
    "        'multipart_words', \n",
    "        'replace_punctuation', \n",
    "        'del_digits']\n",
    "\n",
    "pdata = deepcopy(data)\n",
    "\n",
    "#Preprocess all the sentences and keep the new value in pdata\n",
    "for i in range(len(pdata)):\n",
    "    pdata.iloc[i].s1 = preprocess.pipeline(pdata.iloc[i].s1, flow=flow)\n",
    "    pdata.iloc[i].s2 = preprocess.pipeline(pdata.iloc[i].s2, flow=flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Converting Sentences to Vectors of similarity distances.\n",
    "\n",
    "Every pair of sentences will be convereted to one vector of float values, and the original score will be taken as the final result to get. The same process will be done with preprocessed data and original data, to calculate de impact of preprocess in the machine learning process.\n",
    "\n",
    "The next process must take some time, because the cell must perform 733*2 text to vector conversions, and then obtain 733*43 calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abelma/vnlp/lib/python3.8/site-packages/scipy/spatial/distance.py:714: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/home/abelma/vnlp/lib/python3.8/site-packages/scipy/spatial/distance.py:945: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return (ntf + nft - ntt + n) / (ntf + nft + n)\n",
      "/home/abelma/vnlp/lib/python3.8/site-packages/textsim/tokendists/distances.py:238: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.sqrt(((XA - XB) ** 2 / V).sum())\n",
      "/home/abelma/vnlp/lib/python3.8/site-packages/scipy/spatial/distance.py:1333: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return float(2.0 * ntf * nft / np.array(ntt * nff + ntf * nft))\n"
     ]
    }
   ],
   "source": [
    "mlpdata = pd.DataFrame()\n",
    "mlpdata['score'] = pdata['score']\n",
    "\n",
    "textsimData =pd.DataFrame()\n",
    "#make textsim matrix\n",
    "for metric in textsim.__all_distances__:\n",
    "    observations = []\n",
    "    for i in range(len(pdata)):\n",
    "        observations.append(textsim.__all_distances__[metric](pdata.iloc[i].s1, pdata.iloc[i].s2))\n",
    "    textsimData[metric] = observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(733, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_distance</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>edit_similarity</th>\n",
       "      <th>damerau_levenshtein_distance</th>\n",
       "      <th>jaro_distance</th>\n",
       "      <th>jaro_winkler_distance</th>\n",
       "      <th>hamming_distance</th>\n",
       "      <th>match_rating_comparison</th>\n",
       "      <th>dice_coefficient</th>\n",
       "      <th>lcs_distance</th>\n",
       "      <th>...</th>\n",
       "      <th>matching_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>rogerstanimoto_distance</th>\n",
       "      <th>russellrao_distance</th>\n",
       "      <th>seuclidean_distance</th>\n",
       "      <th>sokalmichener_distance</th>\n",
       "      <th>sokalsneath_distance</th>\n",
       "      <th>sqeuclidean_distance</th>\n",
       "      <th>yule_distance</th>\n",
       "      <th>qgram_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>0.462069</td>\n",
       "      <td>78</td>\n",
       "      <td>0.764647</td>\n",
       "      <td>0.858788</td>\n",
       "      <td>119</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.789474</td>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.769784</td>\n",
       "      <td>32</td>\n",
       "      <td>0.787642</td>\n",
       "      <td>0.872585</td>\n",
       "      <td>121</td>\n",
       "      <td>True</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>4.690416</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>38</td>\n",
       "      <td>0.857150</td>\n",
       "      <td>0.914290</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>148</td>\n",
       "      <td>0.467626</td>\n",
       "      <td>148</td>\n",
       "      <td>0.766001</td>\n",
       "      <td>0.812801</td>\n",
       "      <td>257</td>\n",
       "      <td>True</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-2.777778</td>\n",
       "      <td>-0.162791</td>\n",
       "      <td>7.615773</td>\n",
       "      <td>-2.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>38</td>\n",
       "      <td>0.821830</td>\n",
       "      <td>0.893098</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   binary_distance  levenshtein_distance  edit_similarity  \\\n",
       "0              0.0                    78         0.462069   \n",
       "1              0.0                    32         0.769784   \n",
       "2              0.0                    38         0.672414   \n",
       "3              0.0                   148         0.467626   \n",
       "4              0.0                    38         0.672414   \n",
       "\n",
       "   damerau_levenshtein_distance  jaro_distance  jaro_winkler_distance  \\\n",
       "0                            78       0.764647               0.858788   \n",
       "1                            32       0.787642               0.872585   \n",
       "2                            38       0.857150               0.914290   \n",
       "3                           148       0.766001               0.812801   \n",
       "4                            38       0.821830               0.893098   \n",
       "\n",
       "   hamming_distance  match_rating_comparison  dice_coefficient  lcs_distance  \\\n",
       "0               119                     True          0.622222            77   \n",
       "1               121                     True          0.631579           110   \n",
       "2                70                     True          0.823529            95   \n",
       "3               257                     True          0.444444           158   \n",
       "4               100                     True          0.787879            92   \n",
       "\n",
       "   ...  matching_distance  minkowski_distance  rogerstanimoto_distance  \\\n",
       "0  ...           0.620690                19.0                 0.619048   \n",
       "1  ...           0.478261                11.0                 0.357143   \n",
       "2  ...           0.388889                 7.0                 0.105263   \n",
       "3  ...           0.674419                31.0                -2.777778   \n",
       "4  ...           0.444444                 8.0                 0.200000   \n",
       "\n",
       "   russellrao_distance  seuclidean_distance  sokalmichener_distance  \\\n",
       "0             0.413793             6.000000                0.619048   \n",
       "1             0.260870             4.690416                0.357143   \n",
       "2             0.111111             3.741657                0.105263   \n",
       "3            -0.162791             7.615773               -2.777778   \n",
       "4             0.166667             4.000000                0.200000   \n",
       "\n",
       "   sokalsneath_distance  sqeuclidean_distance  yule_distance  qgram_distance  \n",
       "0              0.604651                  21.0       3.789474        0.622222  \n",
       "1              0.370370                  11.0       0.380952        0.631579  \n",
       "2              0.111111                   7.0       0.000000        0.823529  \n",
       "3              0.000000                  35.0       0.275862        0.444444  \n",
       "4              0.210526                   8.0       0.000000        0.787879  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(textsimData.shape)\n",
    "textsimData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmatrix = mlpdata.merge(textsimData, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(733, 44)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmatrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating the same process with data\n",
    "\n",
    "The original data, without preprocess must be transformed into float numer matrices, or feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abelma/vnlp/lib/python3.8/site-packages/scipy/spatial/distance.py:714: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/home/abelma/vnlp/lib/python3.8/site-packages/scipy/spatial/distance.py:945: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return (ntf + nft - ntt + n) / (ntf + nft + n)\n",
      "/home/abelma/vnlp/lib/python3.8/site-packages/textsim/tokendists/distances.py:238: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.sqrt(((XA - XB) ** 2 / V).sum())\n",
      "/home/abelma/vnlp/lib/python3.8/site-packages/scipy/spatial/distance.py:1333: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return float(2.0 * ntf * nft / np.array(ntt * nff + ntf * nft))\n"
     ]
    }
   ],
   "source": [
    "mldata = pd.DataFrame()\n",
    "mldata['score'] = data['score']\n",
    "\n",
    "textsimData =pd.DataFrame()\n",
    "#make textsim matrix\n",
    "for metric in textsim.__all_distances__:\n",
    "    observations = []\n",
    "    for i in range(len(pdata)):\n",
    "        observations.append(textsim.__all_distances__[metric](data.iloc[i].s1, data.iloc[i].s2))\n",
    "    textsimData[metric] = observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(733, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_distance</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>edit_similarity</th>\n",
       "      <th>damerau_levenshtein_distance</th>\n",
       "      <th>jaro_distance</th>\n",
       "      <th>jaro_winkler_distance</th>\n",
       "      <th>hamming_distance</th>\n",
       "      <th>match_rating_comparison</th>\n",
       "      <th>dice_coefficient</th>\n",
       "      <th>lcs_distance</th>\n",
       "      <th>...</th>\n",
       "      <th>matching_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>rogerstanimoto_distance</th>\n",
       "      <th>russellrao_distance</th>\n",
       "      <th>seuclidean_distance</th>\n",
       "      <th>sokalmichener_distance</th>\n",
       "      <th>sokalsneath_distance</th>\n",
       "      <th>sqeuclidean_distance</th>\n",
       "      <th>yule_distance</th>\n",
       "      <th>qgram_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>0.462069</td>\n",
       "      <td>78</td>\n",
       "      <td>0.764647</td>\n",
       "      <td>0.858788</td>\n",
       "      <td>119</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.789474</td>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.769784</td>\n",
       "      <td>32</td>\n",
       "      <td>0.787642</td>\n",
       "      <td>0.872585</td>\n",
       "      <td>121</td>\n",
       "      <td>True</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>4.690416</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>38</td>\n",
       "      <td>0.857150</td>\n",
       "      <td>0.914290</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>148</td>\n",
       "      <td>0.467626</td>\n",
       "      <td>148</td>\n",
       "      <td>0.766001</td>\n",
       "      <td>0.812801</td>\n",
       "      <td>257</td>\n",
       "      <td>True</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-2.777778</td>\n",
       "      <td>-0.162791</td>\n",
       "      <td>7.615773</td>\n",
       "      <td>-2.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>38</td>\n",
       "      <td>0.821830</td>\n",
       "      <td>0.893098</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   binary_distance  levenshtein_distance  edit_similarity  \\\n",
       "0              0.0                    78         0.462069   \n",
       "1              0.0                    32         0.769784   \n",
       "2              0.0                    38         0.672414   \n",
       "3              0.0                   148         0.467626   \n",
       "4              0.0                    38         0.672414   \n",
       "\n",
       "   damerau_levenshtein_distance  jaro_distance  jaro_winkler_distance  \\\n",
       "0                            78       0.764647               0.858788   \n",
       "1                            32       0.787642               0.872585   \n",
       "2                            38       0.857150               0.914290   \n",
       "3                           148       0.766001               0.812801   \n",
       "4                            38       0.821830               0.893098   \n",
       "\n",
       "   hamming_distance  match_rating_comparison  dice_coefficient  lcs_distance  \\\n",
       "0               119                     True          0.622222            77   \n",
       "1               121                     True          0.631579           110   \n",
       "2                70                     True          0.823529            95   \n",
       "3               257                     True          0.444444           158   \n",
       "4               100                     True          0.787879            92   \n",
       "\n",
       "   ...  matching_distance  minkowski_distance  rogerstanimoto_distance  \\\n",
       "0  ...           0.620690                19.0                 0.619048   \n",
       "1  ...           0.478261                11.0                 0.357143   \n",
       "2  ...           0.388889                 7.0                 0.105263   \n",
       "3  ...           0.674419                31.0                -2.777778   \n",
       "4  ...           0.444444                 8.0                 0.200000   \n",
       "\n",
       "   russellrao_distance  seuclidean_distance  sokalmichener_distance  \\\n",
       "0             0.413793             6.000000                0.619048   \n",
       "1             0.260870             4.690416                0.357143   \n",
       "2             0.111111             3.741657                0.105263   \n",
       "3            -0.162791             7.615773               -2.777778   \n",
       "4             0.166667             4.000000                0.200000   \n",
       "\n",
       "   sokalsneath_distance  sqeuclidean_distance  yule_distance  qgram_distance  \n",
       "0              0.604651                  21.0       3.789474        0.622222  \n",
       "1              0.370370                  11.0       0.380952        0.631579  \n",
       "2              0.111111                   7.0       0.000000        0.823529  \n",
       "3              0.000000                  35.0       0.275862        0.444444  \n",
       "4              0.210526                   8.0       0.000000        0.787879  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(textsimData.shape)\n",
    "textsimData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_distance                  0\n",
      "levenshtein_distance             0\n",
      "edit_similarity                  0\n",
      "damerau_levenshtein_distance     0\n",
      "jaro_distance                    0\n",
      "jaro_winkler_distance            0\n",
      "hamming_distance                 0\n",
      "match_rating_comparison          0\n",
      "dice_coefficient                 0\n",
      "lcs_distance                     0\n",
      "lcs_similarity                   0\n",
      "smith_waterman_distance          0\n",
      "needleman_wunsch_distance        0\n",
      "needleman_wunsch_similarity      0\n",
      "containment_distance             0\n",
      "jaccard_distance                 0\n",
      "overlap_distance                 0\n",
      "matching_coefficient             0\n",
      "matching_coefficient_pablo       0\n",
      "token_containment_distance       0\n",
      "masi_distance                    0\n",
      "interval_distance                0\n",
      "manhattan_distance               0\n",
      "cosine_distance                  0\n",
      "euclidean_distance               0\n",
      "braycurtis_distance              0\n",
      "canberra_distance                0\n",
      "chebyshev_distance               0\n",
      "correlation_distance            21\n",
      "dice_distance                    0\n",
      "token_hamming_distance           0\n",
      "kulsinski_distance               0\n",
      "mahalanobis_distance             0\n",
      "matching_distance                0\n",
      "minkowski_distance               0\n",
      "rogerstanimoto_distance          0\n",
      "russellrao_distance              0\n",
      "seuclidean_distance             17\n",
      "sokalmichener_distance           0\n",
      "sokalsneath_distance             0\n",
      "sqeuclidean_distance             0\n",
      "yule_distance                   33\n",
      "qgram_distance                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Replace n\n",
    "print(textsimData.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        float\n",
       "\u001b[0;31mString form:\u001b[0m inf\n",
       "\u001b[0;31mDocstring:\u001b[0m   Convert a string or number to a floating point number, if possible.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733\n"
     ]
    }
   ],
   "source": [
    "mask = textsimData['yule_distance'] != np.inf\n",
    "print(mask.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_distance                 0\n",
      "levenshtein_distance            0\n",
      "edit_similarity                 0\n",
      "damerau_levenshtein_distance    0\n",
      "jaro_distance                   0\n",
      "jaro_winkler_distance           0\n",
      "hamming_distance                0\n",
      "match_rating_comparison         0\n",
      "dice_coefficient                0\n",
      "lcs_distance                    0\n",
      "lcs_similarity                  0\n",
      "smith_waterman_distance         0\n",
      "needleman_wunsch_distance       0\n",
      "needleman_wunsch_similarity     0\n",
      "containment_distance            0\n",
      "jaccard_distance                0\n",
      "overlap_distance                0\n",
      "matching_coefficient            0\n",
      "matching_coefficient_pablo      0\n",
      "token_containment_distance      0\n",
      "masi_distance                   0\n",
      "interval_distance               0\n",
      "manhattan_distance              0\n",
      "cosine_distance                 0\n",
      "euclidean_distance              0\n",
      "braycurtis_distance             0\n",
      "canberra_distance               0\n",
      "chebyshev_distance              0\n",
      "correlation_distance            0\n",
      "dice_distance                   0\n",
      "token_hamming_distance          0\n",
      "kulsinski_distance              0\n",
      "mahalanobis_distance            0\n",
      "matching_distance               0\n",
      "minkowski_distance              0\n",
      "rogerstanimoto_distance         0\n",
      "russellrao_distance             0\n",
      "seuclidean_distance             0\n",
      "sokalmichener_distance          0\n",
      "sokalsneath_distance            0\n",
      "sqeuclidean_distance            0\n",
      "yule_distance                   0\n",
      "qgram_distance                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Replacing inf by max and -inf by min\n",
    "is_inf = textsimData.yule_distance == np.inf \n",
    "is_ninf = textsimData.yule_distance == -np.inf\n",
    "yule_mean = textsimData.yule_distance[~is_inf & ~is_ninf].mean()\n",
    "textsimData.replace([np.inf, -np.inf], textsimData.yule_distance[~is_inf & ~is_ninf].mean(), inplace=True)\n",
    "col_mask=textsimData.isnull().any(axis=0) \n",
    "row_mask=textsimData.isnull().any(axis=1)\n",
    "textsimData.loc[row_mask,col_mask]\n",
    "textsimData.loc[row_mask,col_mask] = yule_mean\n",
    "\n",
    "mask = textsimData['correlation_distance'] != np.inf\n",
    "textsimData.loc[~mask, 'correlation_distance'] = textsimData.loc[mask, 'correlation_distance'].max()\n",
    "bmask = textsimData['correlation_distance'] != -np.inf\n",
    "textsimData.loc[~bmask, 'correlation_distance'] = textsimData.loc[bmask, 'correlation_distance'].min()\n",
    "mask = textsimData['seuclidean_distance'] != np.inf\n",
    "textsimData.loc[~mask, 'seuclidean_distance'] = textsimData.loc[mask, 'seuclidean_distance'].max()\n",
    "bmask = textsimData['seuclidean_distance'] != -np.inf\n",
    "textsimData.loc[~bmask, 'seuclidean_distance'] = textsimData.loc[bmask, 'seuclidean_distance'].min()\n",
    "print(textsimData.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple inspection of this columns series makes us to evaluate that the 'binary_distance', 'match_rating_comparison', 'damerau_levenshtein_distance' have 0.0 values, boolean values and same value than levenstein_distance respectively. So for the final calculation this columns are useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = textsimData.drop(['binary_distance', 'match_rating_comparison', 'damerau_levenshtein_distance'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(733, 40)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning model\n",
    "\n",
    "[Some kind of Logistic Regression for classification.]\n",
    "\n",
    "[Features, use textsim.calc_all](make a brief description here, and link with github.com/sorice/textsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('sgdregressor', SGDRegressor(max_iter=100))])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "y = data['score']\n",
    "X = exp1\n",
    "reg = make_pipeline(StandardScaler(),SGDRegressor(max_iter=100, tol=1e-3))\n",
    "reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ext.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.5164438])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "test = exp1.iloc[0].to_numpy()\n",
    "test_ext = test.reshape(-1,1).reshape(1,-1)\n",
    "print(test_ext_esc.shape)\n",
    "reg.predict(test_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.25"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['score'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainin Process\n",
    "\n",
    "Train without preprocess\n",
    "\n",
    "Train with preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "[Show differences between scores obtained with/without preprocess]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "* usually we must reduce dimensionality, for better interpretabillity\n",
    "  of the model, less complexity, reduce the training time, avoid \n",
    "  overfitting and gain capacity of generalization \n",
    "\n",
    "* Feature selection process is not objective of this tutorial, but it\n",
    "  is recommended that comparing the list of must important features,\n",
    "  could show how preprocess is relevant for improving results, due to\n",
    "  the straight relation between preprocess and selected features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Applications\n",
    "\n",
    "``preprocess`` library has been used successfully as part of the\n",
    "following projects:\n",
    "\n",
    "- [Text Preprocessing Chapter of MyNLP Course Py3 version](file:///media/abelm/Almacen/Doctorado/Notas_de_la_Investigacion/03_Mi_Curso_Postgrado_Natural_Language_Process/02_Pre-Procesamiento_py3/)\n",
    "- [Text Preprocessing Chapter of MyNLP Course Py2 version](file:///media/abelm/Almacen/Doctorado/Notas_de_la_Investigacion/03_Mi_Curso_Postgrado_Natural_Language_Process/02_Pre-Procesamiento)\n",
    "- [Llanes-corpus similarity experiment active](file:///media/abelm/Almacen/Doctorado/01_Codigos/2016-02_Llanes_simCalcFlow/)\n",
    "- [Next text-reuse experiment active](file:///media/abelm/Almacen/Doctorado/01_Codigos/2015-11-30_Llanes_similarity_Example_8_test_15/)\n",
    "- [repository of my Text-Reuse algorithm](file:///media/abelm/Almacen/Doctorado/00_plag_algh/)\n",
    "\n",
    "### Older uses\n",
    "\n",
    "Older versions of this module. Be careful! Many of this URLs are the ancient versions with different software architectures.\n",
    "\n",
    "- [QtNLP-Linguist module](https://github.com/sorice/QtNLP-Linguist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
